{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aaoun\\OneDrive - cumc.columbia.edu\\Desktop\\HussainiLab\\neuroscikit\\prototypes\\wave_form_sorter\n",
      "c:\\Users\\aaoun\\OneDrive - cumc.columbia.edu\\Desktop\\HussainiLab\\neuroscikit\n",
      "c:\\Users\\aaoun\\OneDrive - cumc.columbia.edu\\Desktop\\HussainiLab\n",
      "c:\\Users\\aaoun\\OneDrive - cumc.columbia.edu\\Desktop\\HussainiLab\\neuroscikit_test_data\\sequential_axona_sessions\n"
     ]
    }
   ],
   "source": [
    "prototype_dir = os.getcwd()\n",
    "print(prototype_dir)\n",
    "\n",
    "parent = os.path.dirname(prototype_dir)\n",
    "parent_dir = os.path.dirname(parent)\n",
    "sys.path.append(parent_dir)\n",
    "print(parent_dir)\n",
    "\n",
    "top_dir = os.path.dirname(parent_dir)\n",
    "print(top_dir)\n",
    "\n",
    "data_dir = top_dir + r'\\neuroscikit_test_data\\sequential_axona_sessions'\n",
    "print(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aaoun\\OneDrive - cumc.columbia.edu\\Desktop\\HussainiLab\\neuroscikit\\prototypes\\wave_form_sorter\n"
     ]
    }
   ],
   "source": [
    "from core.data_spikes import (\n",
    "    SpikeTrain,\n",
    "    SpikeTrainBatch,\n",
    "    Spike,\n",
    "    SpikeCluster,\n",
    "    SpikeClusterBatch,\n",
    ")\n",
    "\n",
    "from x_io.axona.read_tetrode_and_cut import (\n",
    "    load_spike_train_from_paths,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir(data_dir)\n",
    "\n",
    "test1_34 = []\n",
    "test1_35 = []\n",
    "test2_34 = []\n",
    "test2_35 = []\n",
    "\n",
    "for f in files:\n",
    "    if 'Test1' in f and '34' in f:\n",
    "        test1_34.append(f)\n",
    "    elif 'Test1' in f and '35' in f:\n",
    "        test1_35.append(f)\n",
    "    elif 'Test2' in f and '34' in f:\n",
    "        test2_34.append(f)\n",
    "    elif 'Test2' in f and '35' in f:\n",
    "        test2_35.append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "session1 = test1_34\n",
    "session2 = test2_34\n",
    "\n",
    "assert len(session1) == len(session2)\n",
    "\n",
    "session1_tets = []\n",
    "session2_tets = []\n",
    "\n",
    "for i in range(len(session1)):\n",
    "    if 'cut' in session1[i]:\n",
    "        session1_cut = session1[i]\n",
    "    if 'cut' in session2[i]:\n",
    "        session2_cut = session2[i]\n",
    "    file_session_1 = session1[i]\n",
    "    file_session_2 = session2[i]\n",
    "    out1 = file_session_1.split('.')[-1]\n",
    "    out2 = file_session_2.split('.')[-1]\n",
    "    if out1.isnumeric() and 'clu' not in file_session_1:\n",
    "        session1_tets.append(session1[i])\n",
    "    if out2.isnumeric() and 'clu' not in file_session_2:\n",
    "        session2_tets.append(session2[i])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "session1_cut_path = os.path.join(data_dir, session1_cut)\n",
    "session1_tet_path = os.path.join(data_dir, session1_tets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wave\n",
    "\n",
    "\n",
    "waveforms = [[] for i in range(4)]\n",
    "for i in range(4):\n",
    "    channel, empty_cell, cluster_label = load_spike_train_from_paths(session1_cut_path, session1_tet_path, i+1)\n",
    "    cells = channel[:empty_cell][1]\n",
    "    channel_waveforms = channel[:empty_cell][0][0]\n",
    "    timestamps = channel[:empty_cell][0][1]\n",
    "    waveforms[i] = channel_waveforms\n",
    "\n",
    "# wave_vectors = np.array(list(zip(waveforms[0], waveforms[1], waveforms[2]))).squeeze()\n",
    "# wave_vectors = wave_vectors.reshape((wave_vectors.shape[1], wave_vectors.shape[0], wave_vectors.shape[2]))\n",
    "\n",
    "waveforms = np.array(waveforms)\n",
    "waveforms = waveforms.reshape((waveforms.shape[1], waveforms.shape[0], waveforms.shape[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add duration\n",
    "# go overwhich classes use self.timestamp\n",
    "# make Neuron instead of SpikeCluster. Neuron class more extensible, for now merge SpikeTrain fxns, later will want to ahve \n",
    "# summary fxns to see easily if waveform data available or not, maybe make it optional to pass in \n",
    "# check combination of inputs, e.g. if waveforms, need timestamps\n",
    "# e.g. waveforms put in dictionary that holds diff. attributes/stats that can be added to by user --> fxn\n",
    "# also will ahve to add fxn to check that user can add data to the dict\n",
    "\n",
    "# look into error raising that doesnt stop code if exists\n",
    "\n",
    "# spike object --> neuron --> ensemble --> study\n",
    "# ensemble most complex, holds covariates\n",
    "# study ensures conssitency across ensembles, e.g. if one ensemble has this attribute then so do other ensembles\n",
    "# extensible and flexible\n",
    "# study class has functions to return e.g. sorted ensembles/neurons based on added covariate/added attribute\n",
    "\n",
    "# inside file loading classes, make spike objects add to ensemble and in batch_load add ensembles to study\n",
    "\n",
    "# NEw plan: Animal --> Contexts (sess  ions) --> SpikeTrain --> Spike object (event)\n",
    "# Ensemble --> neuron --> spike object\n",
    "\n",
    "# new new plan\n",
    "# Study --> Animal --> Events\n",
    "# Neuron is attribute of event (e.g. spike belonging to a neuron)\n",
    "# polymorphism of events would be spikes (also e.g. lfp)\n",
    "# Ensembles (data structure resulting from group by e.g. spatial, context, maze), can span animal ,session, study\n",
    "\n",
    "session1_dict = {\n",
    "    'sample_length': int(len(timestamps)),\n",
    "    'sample_rate': timestamps[-1]/ len(timestamps),\n",
    "    'spike_times': list(cells),\n",
    "    'cluster_label': list(cluster_label),\n",
    "    'ch1': list(waveforms[0]),\n",
    "    'ch2': list(waveforms[1]),\n",
    "    'ch3': list(waveforms[2]),\n",
    "    'ch4': list(waveforms[3]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = SpikeCluster(session1_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster.get_cluster_spike_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1-13_20210621-34-50x50cm-1500um-Test1.3',\n",
       " '1-13_20210621-34-50x50cm-1500um-Test1.clu.3',\n",
       " '1-13_20210621-34-50x50cm-1500um-Test1.eeg',\n",
       " '1-13_20210621-34-50x50cm-1500um-Test1.egf',\n",
       " '1-13_20210621-34-50x50cm-1500um-Test1.pos',\n",
       " '1-13_20210621-34-50x50cm-1500um-Test1.set',\n",
       " '1-13_20210621-34-50x50cm-1500um-Test1_3.cut']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('envPRISM')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "271de3eaf5512a01a3a2cea9253de8f7a978ec97e5a00bc2131d971ee349090f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
