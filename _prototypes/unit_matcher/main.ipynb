{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' ACTIVE JUPYTER NOTEBOOK TO BATCH RUN UNIT MATCHING ALGORITHM '"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" ACTIVE JUPYTER NOTEBOOK TO BATCH RUN UNIT MATCHING ALGORITHM \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aaoun\\OneDrive - cumc.columbia.edu\\Desktop\\HussainiLab\\neuroscikit\n"
     ]
    }
   ],
   "source": [
    "# Outside imports\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set necessary paths / make project path = ...../neuroscikit/\n",
    "unit_matcher_path = os.getcwd()\n",
    "prototype_path = os.path.abspath(os.path.join(unit_matcher_path, os.pardir))\n",
    "project_path = os.path.abspath(os.path.join(prototype_path, os.pardir))\n",
    "lab_path = os.path.abspath(os.path.join(project_path, os.pardir))\n",
    "sys.path.append(project_path)\n",
    "os.chdir(project_path)\n",
    "print(project_path)\n",
    "\n",
    "# Internal imports\n",
    "\n",
    "# Read write modules\n",
    "from x_io.rw.axona.batch_read import make_study\n",
    "from _prototypes.unit_matcher.read_axona import read_sequential_sessions, temp_read_cut\n",
    "from _prototypes.unit_matcher.write_axona import format_new_cut_file_name\n",
    "\n",
    "# Unit matching modules\n",
    "from _prototypes.unit_matcher.main import format_cut, run_unit_matcher, map_unit_matches_first_session, map_unit_matches_sequential_session\n",
    "from _prototypes.unit_matcher.session import compare_sessions\n",
    "from _prototypes.unit_matcher.waveform import time_index, derivative, derivative2, morphological_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' ONLY EDIT THE SETTINGS IN THE NEXT TWO CELLS '"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" ONLY EDIT THE SETTINGS IN THE NEXT TWO CELLS \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" If a setting is not used for your analysis (e.g. smoothing_factor), just pass in an arbitrary value or pass in 'None' \"\"\"\n",
    "STUDY_SETTINGS = {\n",
    "\n",
    "    'ppm': 511,  # EDIT HERE\n",
    "\n",
    "    'smoothing_factor': None, # EDIT HERE\n",
    "\n",
    "    'useMatchedCut': False,  # EDIT HERE, set to False if you want to use runUnitMatcher, set to True after to load in matched.cut file\n",
    "}\n",
    "\n",
    "\n",
    "# Switch devices to True/False based on what is being used (to be extended for more devices in future)\n",
    "device_settings = {'axona_led_tracker': True, 'implant': True} \n",
    "\n",
    "# Make sure implant metadata is correct, change if not, AT THE MINIMUM leave implant_type: tetrode\n",
    "implant_settings = {'implant_type': 'tetrode', 'implant_geometry': 'square', 'wire_length': 25, 'wire_length_units': 'um', 'implant_units': 'uV'}\n",
    "\n",
    "# WE ASSUME DEVICE AND IMPLANT SETTINGS ARE CONSISTENCE ACROSS SESSIONS, IF THIS IS NOT THE CASE PLEASE LET ME KNOW\n",
    "\n",
    "# Set channel count + add device/implant settings\n",
    "SESSION_SETTINGS = {\n",
    "    'channel_count': 4, # EDIT HERE, default is 4, you can change to other number but code will check how many tetrode files are present and set that to channel copunt regardless\n",
    "    'devices': device_settings, # EDIT HERE\n",
    "    'implant': implant_settings, # EDIT HERE\n",
    "}\n",
    "\n",
    "STUDY_SETTINGS['session'] = SESSION_SETTINGS\n",
    "\n",
    "settings_dict = STUDY_SETTINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = lab_path + r'\\neuroscikit_test_data\\sequential_axona_sessions'\n",
    "# data_dir = lab_path + r'\\neuroscikit_test_data\\single_sequential'\n",
    "\n",
    "# To use in unit matching\n",
    "settings_dict_unmatched = settings_dict\n",
    "settings_dict_unmatched['useMatchedCut'] = False\n",
    "\n",
    "# # To use for loading in matched cut and vizualizing / subsequent analysis\n",
    "# settings_dict_matched = settings_dict\n",
    "# settings_dict_matched['useMatchedCut'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Animal ID set\n",
      "Animal ID set\n",
      "Animal ID set\n",
      "Animal ID set\n",
      "Session data added, spikes sorted by cell\n"
     ]
    }
   ],
   "source": [
    "# Run unit matching on non-matched study, will save new matched cut file. \n",
    "# First all data is loaded ('Animal ID set': Animal1_tet1, Animal1_tet2, etc..)\n",
    "# Then sessions PER animal and spikes per cell are sorted and  ('Session data added (to animal), spikes sorted by cell': Animal1_tet1_ses1, Animal1_tet1_ses2, etc..)\n",
    "# Then unit matching begins Animal1_tet1_ses1_cell_1 vs Animal1_tet1_ses2_cell_1, Animal1_tet1_ses1_cell_1 vs Animal1_tet1_ses2_cell_2, Animal1_tet1_ses1_cell_1 vs Animal1_tet1_ses2_cell_3, etc...\n",
    "unmatched_study = run_unit_matcher([data_dir], settings_dict_unmatched)\n",
    "print('COMPLETED UNIT MATCHING')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings_dict_matched = settings_dict\n",
    "settings_dict_matched['useMatchedCut'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tets = []\n",
    "for ses in unmatched_study.animals[0].sessions:\n",
    "    print(unmatched_study.animals[0].sessions[ses].session_metadata.file_paths)\n",
    "    tets.append(unmatched_study.animals[0].sessions[ses].session_metadata.file_paths['tet'])\n",
    "    print(unmatched_study.animals[0].sessions[ses].datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(tets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_study = make_study([data_dir], settings_dict_matched)\n",
    "matched_study.make_animals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for animal in matched_study.animals:\n",
    "    print('New Animal')\n",
    "    for session in animal.sessions.values():\n",
    "        print('Session date & time: ' + str(session.datetime))\n",
    "        print('Matched cell ids: ' + str(np.unique(session.get_spike_data()['spike_cluster'].cluster_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session1 = matched_study.animals[0].sessions['session_1']\n",
    "ensemble1 = matched_study.animals[0].ensembles['session_1']\n",
    "session2 = matched_study.animals[0].sessions['session_2']\n",
    "ensemble2 = matched_study.animals[0].ensembles['session_2']\n",
    "\n",
    "unmatched_ensembles1 = unmatched_study.animals[0].ensembles['session_1']\n",
    "unmatched_ensembles2 = unmatched_study.animals[0].ensembles['session_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Plot session 1 (left) & session 2 (right) MATCHED units \"\"\"\n",
    "\n",
    "pair_count = len(ensemble1.get_label_ids())\n",
    "\n",
    "for i in range(pair_count):\n",
    "# for i in range(2):\n",
    "\n",
    "    fig = plt.figure(figsize=(6,12))\n",
    "\n",
    "    axes = []\n",
    "\n",
    "    waveforms1 = ensemble1.cells[i].signal\n",
    "    waveforms2 = ensemble2.cells[i].signal\n",
    "\n",
    "    avg_waveforms1 = np.mean(waveforms1, axis=0)\n",
    "    avg_waveforms2 = np.mean(waveforms2, axis=0)\n",
    "\n",
    "    assert waveforms1.shape[1] == avg_waveforms1.shape[0]\n",
    "\n",
    "    for j in range(0,avg_waveforms1.shape[0]*2,2):\n",
    "        ax1 = plt.subplot(avg_waveforms1.shape[0],2,j+1)\n",
    "        ax2 = plt.subplot(avg_waveforms1.shape[0],2,j+2)\n",
    "\n",
    "        ax1.plot(waveforms1[:,int(j/2)].T, color='gray', lw=0.5, alpha=0.5)\n",
    "        ax2.plot(waveforms2[:,int(j/2)].T, color='gray', lw=0.5, alpha=0.5)\n",
    "\n",
    "        ax1.plot(avg_waveforms1[int(j/2)], color='k', lw=2)\n",
    "        ax2.plot(avg_waveforms2[int(j/2)], color='k', lw=2)\n",
    "\n",
    "        ax1.set_title('Channel ' + str(int(j/2+1)))\n",
    "        ax2.set_title('Channel ' + str(int(j/2+1)))\n",
    "\n",
    "        axes.append(ax1)\n",
    "        axes.append(ax2)\n",
    "\n",
    "    for ax in axes:\n",
    "        ax.set_xlabel('Bin Number')\n",
    "        ax.set_ylabel('Waveform')\n",
    "\n",
    "    fig.suptitle('Session 1 (left) & 2 (right) - Unit ' + str(i+1))\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('.winenv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a483150cdaf8e1b13d926fcb03f3f838be63af26b5c48b7f4f7dd963c17f4da9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
