{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick directory --> load all data into study dict\n",
    "\n",
    "# study --> A1, A2, ... --> A1S1, A1S2, ... A2S1, A2S2, ... --> A1S1C1, A1S1C2, ..., A1S2C1, ...\n",
    "\n",
    "# sort cell data, match across waveforms\n",
    "\n",
    "# batch run spikeAnalysisGUI (firing data) {batch_ratemaps.py}\n",
    "\n",
    "# batch run spikeWidthGUI (spike width)\n",
    "\n",
    "# batch run PowerSpectrum.vel --> save output LFP data and load into python\n",
    "\n",
    "# batch run hfoGUI (LFP vizualization) \n",
    "\n",
    "# batch run PRISM/neurofunc (field properties) {batch_ratemaps.py}\n",
    "\n",
    "# batch run odor/object analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" ACTIVE JUPYTER NOTEBOOK TO BATCH RUN UNIT MATCHING ALGORITHM \"\"\"\n",
    "\n",
    "# To be able to make edits to repo without having to restart notebook\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aaoun\\OneDrive - cumc.columbia.edu\\Desktop\\HussainiLab\\neuroscikit\n"
     ]
    }
   ],
   "source": [
    "# Outside imports\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set necessary paths / make project path = ...../neuroscikit/\n",
    "unit_matcher_path = os.getcwd()\n",
    "prototype_path = os.path.abspath(os.path.join(unit_matcher_path, os.pardir))\n",
    "project_path = os.path.abspath(os.path.join(prototype_path, os.pardir))\n",
    "lab_path = os.path.abspath(os.path.join(project_path, os.pardir))\n",
    "out_path = os.path.abspath(os.path.join(lab_path, os.pardir))\n",
    "sys.path.append(project_path)\n",
    "os.chdir(project_path)\n",
    "print(project_path)\n",
    "\n",
    "# Internal imports\n",
    "\n",
    "# Read write modules\n",
    "from x_io.rw.axona.batch_read import make_study\n",
    "from _prototypes.unit_matcher.read_axona import read_sequential_sessions, temp_read_cut\n",
    "from _prototypes.unit_matcher.write_axona import format_new_cut_file_name\n",
    "\n",
    "# Unit matching modules\n",
    "from _prototypes.unit_matcher.main import format_cut, run_unit_matcher, map_unit_matches_first_session, map_unit_matches_sequential_session\n",
    "from _prototypes.unit_matcher.session import compare_sessions\n",
    "from _prototypes.unit_matcher.waveform import time_index, derivative, derivative2, morphological_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" If a setting is not used for your analysis (e.g. smoothing_factor), just pass in an arbitrary value or pass in 'None' \"\"\"\n",
    "STUDY_SETTINGS = {\n",
    "\n",
    "    'ppm': 511,  # EDIT HERE\n",
    "\n",
    "    'smoothing_factor': None, # EDIT HERE\n",
    "\n",
    "    'useMatchedCut': False,  # EDIT HERE, set to False if you want to use runUnitMatcher, set to True after to load in matched.cut file\n",
    "}\n",
    "\n",
    "\n",
    "# Switch devices to True/False based on what is used in the acquisition (to be extended for more devices in future)\n",
    "device_settings = {'axona_led_tracker': True, 'implant': True} \n",
    "\n",
    "# Make sure implant metadata is correct, change if not, AT THE MINIMUM leave implant_type: tetrode\n",
    "implant_settings = {'implant_type': 'tetrode', 'implant_geometry': 'square', 'wire_length': 25, 'wire_length_units': 'um', 'implant_units': 'uV'}\n",
    "\n",
    "# WE ASSUME DEVICE AND IMPLANT SETTINGS ARE CONSISTENCE ACROSS SESSIONS\n",
    "\n",
    "# Set channel count + add device/implant settings\n",
    "SESSION_SETTINGS = {\n",
    "    'channel_count': 4, # EDIT HERE, default is 4, you can change to other number but code will check how many tetrode files are present and set that to channel copunt regardless\n",
    "    'devices': device_settings, # EDIT HERE\n",
    "    'implant': implant_settings, # EDIT HERE\n",
    "}\n",
    "\n",
    "STUDY_SETTINGS['session'] = SESSION_SETTINGS\n",
    "\n",
    "settings_dict = STUDY_SETTINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = out_path + r'\\20180530-ROUND-3300-1X2B3A' \n",
    "\n",
    "# To use in unit matching\n",
    "settings_dict_unmatched = settings_dict\n",
    "settings_dict_unmatched['useMatchedCut'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unmatched_study = run_unit_matcher([data_dir], settings_dict_unmatched)\n",
    "# print('COMPLETED UNIT MATCHING')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Animal ID set\n",
      "Animal ID set\n",
      "Animal ID set\n",
      "Animal ID set\n",
      "Session data added, spikes sorted by cell\n",
      "Session data added, spikes sorted by cell\n",
      "Session data added, spikes sorted by cell\n",
      "Session data added, spikes sorted by cell\n"
     ]
    }
   ],
   "source": [
    "study = make_study([data_dir], settings_dict_unmatched)\n",
    "study.make_animals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_event_times(study):\n",
    "    agg_events = []\n",
    "    for animal in study.animals:\n",
    "        for ses in animal.ensembles:\n",
    "            for cell in animal.ensembles[ses].cells:\n",
    "                agg_events.append(cell.event_times)\n",
    "    return agg_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_event_times = aggregate_event_times(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.14583333e-02, 3.16270833e-01, 8.44020833e-01, ...,\n",
       "       2.40162396e+02, 2.40180646e+02, 2.40461875e+02])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit (system)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "271de3eaf5512a01a3a2cea9253de8f7a978ec97e5a00bc2131d971ee349090f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
